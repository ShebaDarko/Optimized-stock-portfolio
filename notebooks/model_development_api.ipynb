{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "315e0359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to /home/Downloads/stock_sample_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the parquet file into a pandas DataFrame\n",
    "file_path = \"/home/data/Downloads/stock_sample_data.parquet\"\n",
    "df = pd.read_parquet(file_path)  # Use file_path instead of 'data.parquet'\n",
    "\n",
    "\n",
    "output_file_path = \"/home/data/Downloads/stock_sample_data.xlsx\"\n",
    "df.to_csv(output_file_path, sep='\\t', index=False)  # Save as tab-separated values\n",
    "\n",
    "print(f\"Data saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92fd5a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69715/2070849963.py:5: DtypeWarning: Columns (1,2,3,4,5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path, sep='\\t', header=None)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (make sure to specify the correct file path)\n",
    "file_path = \"/home/data/Downloads/stock_sample_data.xlsx\" # Adjust this to your file location\n",
    "data = pd.read_csv(file_path, sep='\\t', header=None)\n",
    "\n",
    "# Assign appropriate column names\n",
    "data.columns = ['date', 'open', 'high', 'low', 'close', 'volume', 'context_id', 'day']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16a05fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All rows of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>context_id</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>56.330471</td>\n",
       "      <td>56.464592</td>\n",
       "      <td>48.193848</td>\n",
       "      <td>43.463036</td>\n",
       "      <td>4674353</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>0.936384</td>\n",
       "      <td>1.004464</td>\n",
       "      <td>0.907924</td>\n",
       "      <td>0.844004</td>\n",
       "      <td>535796800</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>15.823756</td>\n",
       "      <td>16.160433</td>\n",
       "      <td>15.599306</td>\n",
       "      <td>8.327244</td>\n",
       "      <td>10635087</td>\n",
       "      <td>ABT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>1.409722</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>1.263889</td>\n",
       "      <td>1.277778</td>\n",
       "      <td>433800</td>\n",
       "      <td>ACGL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>16.812500</td>\n",
       "      <td>16.875000</td>\n",
       "      <td>16.062500</td>\n",
       "      <td>16.274672</td>\n",
       "      <td>7384400</td>\n",
       "      <td>ADBE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770135</th>\n",
       "      <td>2024-10-15</td>\n",
       "      <td>137.630005</td>\n",
       "      <td>138.469894</td>\n",
       "      <td>137.210007</td>\n",
       "      <td>137.785004</td>\n",
       "      <td>347338</td>\n",
       "      <td>XYL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770136</th>\n",
       "      <td>2024-10-15</td>\n",
       "      <td>134.210007</td>\n",
       "      <td>134.669998</td>\n",
       "      <td>132.723999</td>\n",
       "      <td>133.779999</td>\n",
       "      <td>513843</td>\n",
       "      <td>YUM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770137</th>\n",
       "      <td>2024-10-15</td>\n",
       "      <td>103.510002</td>\n",
       "      <td>105.970001</td>\n",
       "      <td>103.785004</td>\n",
       "      <td>105.294998</td>\n",
       "      <td>436167</td>\n",
       "      <td>ZBH</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770138</th>\n",
       "      <td>2024-10-15</td>\n",
       "      <td>376.739990</td>\n",
       "      <td>380.034393</td>\n",
       "      <td>374.040009</td>\n",
       "      <td>374.859985</td>\n",
       "      <td>143956</td>\n",
       "      <td>ZBRA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770139</th>\n",
       "      <td>2024-10-15</td>\n",
       "      <td>192.279999</td>\n",
       "      <td>195.809998</td>\n",
       "      <td>192.184998</td>\n",
       "      <td>193.877594</td>\n",
       "      <td>505126</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2770140 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date        open        high         low       close  \\\n",
       "0        2000-01-03   56.330471   56.464592   48.193848   43.463036   \n",
       "1        2000-01-03    0.936384    1.004464    0.907924    0.844004   \n",
       "2        2000-01-03   15.823756   16.160433   15.599306    8.327244   \n",
       "3        2000-01-03    1.409722    1.416667    1.263889    1.277778   \n",
       "4        2000-01-03   16.812500   16.875000   16.062500   16.274672   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "2770135  2024-10-15  137.630005  138.469894  137.210007  137.785004   \n",
       "2770136  2024-10-15  134.210007  134.669998  132.723999  133.779999   \n",
       "2770137  2024-10-15  103.510002  105.970001  103.785004  105.294998   \n",
       "2770138  2024-10-15  376.739990  380.034393  374.040009  374.859985   \n",
       "2770139  2024-10-15  192.279999  195.809998  192.184998  193.877594   \n",
       "\n",
       "            volume context_id  day  \n",
       "0          4674353          A    0  \n",
       "1        535796800       AAPL    0  \n",
       "2         10635087        ABT    0  \n",
       "3           433800       ACGL    0  \n",
       "4          7384400       ADBE    0  \n",
       "...            ...        ...  ...  \n",
       "2770135     347338        XYL    1  \n",
       "2770136     513843        YUM    1  \n",
       "2770137     436167        ZBH    1  \n",
       "2770138     143956       ZBRA    1  \n",
       "2770139     505126        ZTS    1  \n",
       "\n",
       "[2770140 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic information about the dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2770140 entries, 0 to 2770139\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   date        object \n",
      " 1   open        float64\n",
      " 2   high        float64\n",
      " 3   low         float64\n",
      " 4   close       float64\n",
      " 5   volume      int64  \n",
      " 6   context_id  object \n",
      " 7   day         int64  \n",
      "dtypes: float64(4), int64(2), object(2)\n",
      "memory usage: 169.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>close</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volume</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context_id</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Missing Values\n",
       "date                     0\n",
       "open                     0\n",
       "high                     0\n",
       "low                      0\n",
       "close                    0\n",
       "volume                   0\n",
       "context_id               0\n",
       "day                      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (make sure to specify the correct file path)\n",
    "file_path = \"/home/data/Downloads/stock_sample_data.xlsx\"  # Adjust this to your file location\n",
    "data = pd.read_csv(file_path, sep='\\t')  # Use the appropriate separator\n",
    "\n",
    "# Assign column names\n",
    "data.columns = ['date', 'open', 'high', 'low', 'close', 'volume', 'context_id', 'day']\n",
    "\n",
    "# Convert relevant columns to numeric, handling non-numeric values\n",
    "data['open'] = pd.to_numeric(data['open'], errors='coerce')\n",
    "data['high'] = pd.to_numeric(data['high'], errors='coerce')\n",
    "data['low'] = pd.to_numeric(data['low'], errors='coerce')\n",
    "data['close'] = pd.to_numeric(data['close'], errors='coerce')\n",
    "data['volume'] = pd.to_numeric(data['volume'], errors='coerce')\n",
    "\n",
    "# Display all rows of the dataset\n",
    "print(\"All rows of the dataset:\")\n",
    "display(data)  # Display the entire DataFrame\n",
    "\n",
    "# Get basic information about the dataset\n",
    "print(\"\\nBasic information about the dataset:\")\n",
    "df_info = data.info()  # Get information about the DataFrame\n",
    "display(pd.DataFrame(df_info))  # Convert info to DataFrame and display\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in the dataset:\")\n",
    "df_missing = data.isnull().sum()  # Check for missing values\n",
    "display(pd.DataFrame(df_missing, columns=['Missing Values']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "886f349d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Head:\n",
      "         date       open       high        low      close     volume  \\\n",
      "0  2000-01-03  56.330471  56.464592  48.193848  43.463036    4674353   \n",
      "1  2000-01-03   0.936384   1.004464   0.907924   0.844004  535796800   \n",
      "2  2000-01-03  15.823756  16.160433  15.599306   8.327244   10635087   \n",
      "3  2000-01-03   1.409722   1.416667   1.263889   1.277778     433800   \n",
      "4  2000-01-03  16.812500  16.875000  16.062500  16.274672    7384400   \n",
      "\n",
      "  context_id  day  \n",
      "0          A    0  \n",
      "1       AAPL    0  \n",
      "2        ABT    0  \n",
      "3       ACGL    0  \n",
      "4       ADBE    0  \n",
      "Column Names:\n",
      "Index(['date', 'open', 'high', 'low', 'close', 'volume', 'context_id', 'day'], dtype='object')\n",
      "NaN Values Check:\n",
      "date          0\n",
      "open          0\n",
      "high          0\n",
      "low           0\n",
      "close         0\n",
      "volume        0\n",
      "context_id    0\n",
      "day           0\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Series.cov() missing 1 required positional argument: 'other'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Calculate expected returns and covariance matrix\u001b[39;00m\n\u001b[1;32m     42\u001b[0m expected_returns \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturns\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m252\u001b[39m  \u001b[38;5;66;03m# Annualize returns\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m cov_matrix \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturns\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcov() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m252\u001b[39m  \u001b[38;5;66;03m# Annualize covariance\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Initial budget\u001b[39;00m\n\u001b[1;32m     46\u001b[0m initial_budget \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Series.cov() missing 1 required positional argument: 'other'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Load the dataset (make sure to specify the correct file path)\n",
    "file_path = \"/home/data/Downloads/stock_sample_data.xlsx\"  # Adjust this to your file location\n",
    "data = pd.read_csv(file_path, sep='\\t')  # Use the appropriate separator\n",
    "# Read the CSV file\n",
    "\n",
    "# Print the first few rows of the DataFrame to check the data structure\n",
    "print(\"Data Head:\")\n",
    "print(data.head())\n",
    "\n",
    "# Check the column names and adjust if necessary\n",
    "print(\"Column Names:\")\n",
    "print(data.columns)\n",
    "\n",
    "# Assign column names (assuming this matches the structure of your CSV)\n",
    "data.columns = ['date', 'open', 'high', 'low', 'close', 'volume', 'context_id', 'day']\n",
    "\n",
    "# Convert relevant columns to numeric, handling non-numeric values\n",
    "data['open'] = pd.to_numeric(data['open'], errors='coerce')\n",
    "data['high'] = pd.to_numeric(data['high'], errors='coerce')\n",
    "data['low'] = pd.to_numeric(data['low'], errors='coerce')\n",
    "data['close'] = pd.to_numeric(data['close'], errors='coerce')\n",
    "data['volume'] = pd.to_numeric(data['volume'], errors='coerce')\n",
    "\n",
    "# Check if there are any NaN values after conversion\n",
    "print(\"NaN Values Check:\")\n",
    "print(data.isna().sum())\n",
    "\n",
    "# Drop rows with NaN values to avoid calculation issues\n",
    "data.dropna(subset=['open', 'high', 'low', 'close', 'volume'], inplace=True)\n",
    "\n",
    "# Calculate daily returns based on 'close' prices\n",
    "data['returns'] = data['close'].pct_change()  # Calculate percentage change in 'close' prices\n",
    "\n",
    "# Drop NaN values generated from pct_change\n",
    "data.dropna(subset=['returns'], inplace=True)\n",
    "\n",
    "# Calculate expected returns and covariance matrix\n",
    "expected_returns = data['returns'].mean() * 252  # Annualize returns\n",
    "cov_matrix = data['returns'].cov() * 252  # Annualize covariance\n",
    "\n",
    "# Initial budget\n",
    "initial_budget = 1000\n",
    "\n",
    "# Portfolio optimization function\n",
    "def portfolio_optimization(weights):\n",
    "    portfolio_return = np.dot(weights, expected_returns)\n",
    "    portfolio_risk = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "    return -portfolio_return / portfolio_risk  # Negative Sharpe ratio for minimization\n",
    "\n",
    "# Constraints and bounds\n",
    "constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})  # Weights must sum to 1\n",
    "bounds = tuple((0, 1) for _ in range(len(expected_returns)))  # Weights between 0 and 1\n",
    "\n",
    "# Initial guess (equal distribution)\n",
    "initial_weights = [1 / len(expected_returns)] * len(expected_returns)\n",
    "\n",
    "# Optimize\n",
    "result = minimize(portfolio_optimization, initial_weights, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "\n",
    "# Optimized weights\n",
    "optimized_weights = result.x\n",
    "\n",
    "# Calculate amount to invest in each stock\n",
    "investment_amounts = [weight * initial_budget for weight in optimized_weights]\n",
    "\n",
    "# Output results\n",
    "stock_investments = pd.Series(investment_amounts, index=data['context_id'].unique())\n",
    "print(\"Optimized Stock Investments:\")\n",
    "print(stock_investments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af49b649",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/data/Downloads/stock_sample_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load the dataset (make sure to specify the correct file path)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/data/Downloads/stock_sample_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Use the correct CSV file path\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)  \u001b[38;5;66;03m# Read the CSV file\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Print the first few rows of the DataFrame to check the data structure\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData Head:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/data/Downloads/stock_sample_data.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Load the dataset (make sure to specify the correct file path)\n",
    "file_path = \"/home/bathsheba/Downloads/stock_sample_data.csv\"  # Use the correct CSV file path\n",
    "data = pd.read_csv(file_path)  # Read the CSV file\n",
    "\n",
    "# Print the first few rows of the DataFrame to check the data structure\n",
    "print(\"Data Head:\")\n",
    "print(data.head())\n",
    "\n",
    "# Check the column names and adjust if necessary\n",
    "print(\"Column Names:\")\n",
    "print(data.columns)\n",
    "\n",
    "# Assign column names (assuming this matches the structure of your CSV)\n",
    "data.columns = ['date', 'open', 'high', 'low', 'close', 'volume', 'context_id', 'day']\n",
    "\n",
    "# Convert relevant columns to numeric, handling non-numeric values\n",
    "data['open'] = pd.to_numeric(data['open'], errors='coerce')\n",
    "data['high'] = pd.to_numeric(data['high'], errors='coerce')\n",
    "data['low'] = pd.to_numeric(data['low'], errors='coerce')\n",
    "data['close'] = pd.to_numeric(data['close'], errors='coerce')\n",
    "data['volume'] = pd.to_numeric(data['volume'], errors='coerce')\n",
    "\n",
    "# Check if there are any NaN values after conversion\n",
    "print(\"NaN Values Check:\")\n",
    "print(data.isna().sum())\n",
    "\n",
    "# Drop rows with NaN values to avoid calculation issues\n",
    "data.dropna(subset=['open', 'high', 'low', 'close', 'volume'], inplace=True)\n",
    "\n",
    "# Calculate daily returns based on 'close' prices\n",
    "data['returns'] = data['close'].pct_change()  # Calculate percentage change in 'close' prices\n",
    "\n",
    "# Drop NaN values generated from pct_change\n",
    "data.dropna(subset=['returns'], inplace=True)\n",
    "\n",
    "# Pivot the DataFrame to get returns for multiple stocks\n",
    "# This assumes that 'context_id' differentiates between different stocks\n",
    "returns_data = data.pivot_table(index='date', columns='context_id', values='returns')\n",
    "\n",
    "# Drop rows with NaN values\n",
    "returns_data.dropna(inplace=True)\n",
    "\n",
    "# Calculate expected returns and covariance matrix\n",
    "expected_returns = returns_data.mean() * 252  # Annualize returns\n",
    "cov_matrix = returns_data.cov() * 252  # Annualize covariance\n",
    "\n",
    "# Initial budget\n",
    "initial_budget = 1000\n",
    "\n",
    "# Portfolio optimization function\n",
    "def portfolio_optimization(weights):\n",
    "    portfolio_return = np.dot(weights, expected_returns)\n",
    "    portfolio_risk = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "    return -portfolio_return / portfolio_risk  # Negative Sharpe ratio for minimization\n",
    "\n",
    "# Constraints and bounds\n",
    "constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})  # Weights must sum to 1\n",
    "bounds = tuple((0, 1) for _ in range(len(expected_returns)))  # Weights between 0 and 1\n",
    "\n",
    "# Initial guess (equal distribution)\n",
    "initial_weights = [1 / len(expected_returns)] * len(expected_returns)\n",
    "\n",
    "# Optimize\n",
    "result = minimize(portfolio_optimization, initial_weights, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "\n",
    "# Optimized weights\n",
    "optimized_weights = result.x\n",
    "\n",
    "# Calculate amount to invest in each stock\n",
    "investment_amounts = [weight * initial_budget for weight in optimized_weights]\n",
    "\n",
    "# Output results\n",
    "stock_investments = pd.Series(investment_amounts, index=expected_returns.index)\n",
    "print(\"Optimized Stock Investments:\")\n",
    "print(stock_investments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "346f77d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Head:\n",
      "         date       open       high        low      close     volume  \\\n",
      "0  2000-01-03  56.330471  56.464592  48.193848  43.463036    4674353   \n",
      "1  2000-01-03   0.936384   1.004464   0.907924   0.844004  535796800   \n",
      "2  2000-01-03  15.823756  16.160433  15.599306   8.327244   10635087   \n",
      "3  2000-01-03   1.409722   1.416667   1.263889   1.277778     433800   \n",
      "4  2000-01-03  16.812500  16.875000  16.062500  16.274672    7384400   \n",
      "\n",
      "  context_id  day  \n",
      "0          A    0  \n",
      "1       AAPL    0  \n",
      "2        ABT    0  \n",
      "3       ACGL    0  \n",
      "4       ADBE    0  \n",
      "Column Names:\n",
      "Index(['date', 'open', 'high', 'low', 'close', 'volume', 'context_id', 'day'], dtype='object')\n",
      "NaN Values Check:\n",
      "date          0\n",
      "open          0\n",
      "high          0\n",
      "low           0\n",
      "close         0\n",
      "volume        0\n",
      "context_id    0\n",
      "day           0\n",
      "dtype: int64\n",
      "Optimized Stock Investments:\n",
      "context_id\n",
      "A       1.988051\n",
      "AAPL    1.988159\n",
      "ABBV    1.988051\n",
      "ABNB    1.988221\n",
      "ABT     1.988051\n",
      "          ...   \n",
      "XYL     1.988105\n",
      "YUM     1.988051\n",
      "ZBH     1.988092\n",
      "ZBRA    1.988051\n",
      "ZTS     1.988051\n",
      "Length: 503, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Load the dataset (make sure to specify the correct file path)\n",
    "file_path = \"/home/bathsheba/Downloads/stock_sample_data.xlsx\"  # Adjust this to your file location\n",
    "data = pd.read_csv(file_path, sep='\\t')  # Use the appropriate separator\n",
    "\n",
    "# Print the first few rows of the DataFrame to check the data structure\n",
    "print(\"Data Head:\")\n",
    "print(data.head())\n",
    "\n",
    "# Check the column names and adjust if necessary\n",
    "print(\"Column Names:\")\n",
    "print(data.columns)\n",
    "\n",
    "# Assign column names (assuming this matches the structure of your CSV)\n",
    "data.columns = ['date', 'open', 'high', 'low', 'close', 'volume', 'context_id', 'day']\n",
    "\n",
    "# Convert relevant columns to numeric, handling non-numeric values\n",
    "data['open'] = pd.to_numeric(data['open'], errors='coerce')\n",
    "data['high'] = pd.to_numeric(data['high'], errors='coerce')\n",
    "data['low'] = pd.to_numeric(data['low'], errors='coerce')\n",
    "data['close'] = pd.to_numeric(data['close'], errors='coerce')\n",
    "data['volume'] = pd.to_numeric(data['volume'], errors='coerce')\n",
    "\n",
    "# Check if there are any NaN values after conversion\n",
    "print(\"NaN Values Check:\")\n",
    "print(data.isna().sum())\n",
    "\n",
    "# Drop rows with NaN values to avoid calculation issues\n",
    "data.dropna(subset=['open', 'high', 'low', 'close', 'volume'], inplace=True)\n",
    "\n",
    "# Calculate daily returns based on 'close' prices\n",
    "data['returns'] = data['close'].pct_change()  # Calculate percentage change in 'close' prices\n",
    "\n",
    "# Drop NaN values generated from pct_change\n",
    "data.dropna(subset=['returns'], inplace=True)\n",
    "\n",
    "# Pivot the data to get stock returns in separate columns\n",
    "returns_df = data.pivot_table(values='returns', index='date', columns='context_id')\n",
    "returns_df = returns_df.dropna()  # Drop rows with NaN values in returns\n",
    "\n",
    "# Calculate expected returns and covariance matrix for all stocks\n",
    "expected_returns = returns_df.mean() * 252  # Annualize returns\n",
    "cov_matrix = returns_df.cov() * 252  # Annualize covariance\n",
    "\n",
    "# Initial budget\n",
    "initial_budget = 1000\n",
    "\n",
    "# Portfolio optimization function\n",
    "def portfolio_optimization(weights):\n",
    "    portfolio_return = np.dot(weights, expected_returns)\n",
    "    portfolio_risk = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "    return -portfolio_return / portfolio_risk  # Negative Sharpe ratio for minimization\n",
    "\n",
    "# Constraints and bounds\n",
    "constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})  # Weights must sum to 1\n",
    "bounds = tuple((0, 1) for _ in range(len(expected_returns)))  # Weights between 0 and 1\n",
    "\n",
    "# Initial guess (equal distribution)\n",
    "initial_weights = [1 / len(expected_returns)] * len(expected_returns)\n",
    "\n",
    "# Optimize\n",
    "result = minimize(portfolio_optimization, initial_weights, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "\n",
    "# Optimized weights\n",
    "optimized_weights = result.x\n",
    "\n",
    "# Calculate amount to invest in each stock\n",
    "investment_amounts = [weight * initial_budget for weight in optimized_weights]\n",
    "\n",
    "# Output results\n",
    "stock_investments = pd.Series(investment_amounts, index=expected_returns.index)\n",
    "print(\"Optimized Stock Investments:\")\n",
    "print(stock_investments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a445e21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Data:\n",
      "               date        open        high         low       close  \\\n",
      "0        2000-01-03   56.330471   56.464592   48.193848   43.463036   \n",
      "1        2000-01-03    0.936384    1.004464    0.907924    0.844004   \n",
      "2        2000-01-03   15.823756   16.160433   15.599306    8.327244   \n",
      "3        2000-01-03    1.409722    1.416667    1.263889    1.277778   \n",
      "4        2000-01-03   16.812500   16.875000   16.062500   16.274672   \n",
      "...             ...         ...         ...         ...         ...   \n",
      "2770135  2024-10-15  137.630005  138.469894  137.210007  137.785004   \n",
      "2770136  2024-10-15  134.210007  134.669998  132.723999  133.779999   \n",
      "2770137  2024-10-15  103.510002  105.970001  103.785004  105.294998   \n",
      "2770138  2024-10-15  376.739990  380.034393  374.040009  374.859985   \n",
      "2770139  2024-10-15  192.279999  195.809998  192.184998  193.877594   \n",
      "\n",
      "            volume context_id  day  \n",
      "0          4674353          A    0  \n",
      "1        535796800       AAPL    0  \n",
      "2         10635087        ABT    0  \n",
      "3           433800       ACGL    0  \n",
      "4          7384400       ADBE    0  \n",
      "...            ...        ...  ...  \n",
      "2770135     347338        XYL    1  \n",
      "2770136     513843        YUM    1  \n",
      "2770137     436167        ZBH    1  \n",
      "2770138     143956       ZBRA    1  \n",
      "2770139     505126        ZTS    1  \n",
      "\n",
      "[2770140 rows x 8 columns]\n",
      "Column Names:\n",
      "Index(['date', 'open', 'high', 'low', 'close', 'volume', 'context_id', 'day'], dtype='object')\n",
      "NaN Values Check:\n",
      "date          0\n",
      "open          0\n",
      "high          0\n",
      "low           0\n",
      "close         0\n",
      "volume        0\n",
      "context_id    0\n",
      "day           0\n",
      "dtype: int64\n",
      "Optimized Stock Investments:\n",
      "context_id\n",
      "A       1.988051\n",
      "AAPL    1.988159\n",
      "ABBV    1.988051\n",
      "ABNB    1.988221\n",
      "ABT     1.988051\n",
      "          ...   \n",
      "XYL     1.988105\n",
      "YUM     1.988051\n",
      "ZBH     1.988092\n",
      "ZBRA    1.988051\n",
      "ZTS     1.988051\n",
      "Length: 503, dtype: float64\n",
      "Complete Returns DataFrame:\n",
      "context_id         A      AAPL      ABBV      ABNB       ABT      ACGL  \\\n",
      "date                                                                     \n",
      "2024-07-08 -0.278869  0.807876 -0.274887 -0.079054 -0.331528 -0.032694   \n",
      "2024-07-09 -0.284509  0.824105 -0.270977 -0.084496 -0.336808 -0.030697   \n",
      "2024-07-10 -0.270146  0.834273 -0.284049 -0.088647 -0.324907 -0.048838   \n",
      "2024-07-11 -0.245359  0.740321 -0.259313 -0.132828 -0.290204 -0.063980   \n",
      "2024-07-12 -0.255464  0.744234 -0.267262 -0.130089 -0.293705 -0.069162   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "2024-10-09 -0.227197  0.585221 -0.151564 -0.304288 -0.144217 -0.024666   \n",
      "2024-10-10 -0.249408  0.604596 -0.151458 -0.316645 -0.129433 -0.014876   \n",
      "2024-10-11 -0.244166  0.582186 -0.146605 -0.307894 -0.136012 -0.014812   \n",
      "2024-10-14 -0.241109  0.603466 -0.154129 -0.311066 -0.130128 -0.052537   \n",
      "2024-10-15 -0.247080  0.612616 -0.177461 -0.308472 -0.122586 -0.054137   \n",
      "\n",
      "context_id       ACN      ADBE       ADI       ADM  ...       WTW        WY  \\\n",
      "date                                                ...                       \n",
      "2024-07-08  2.022122  0.937676 -0.596062 -0.729621  ... -0.190159 -0.894157   \n",
      "2024-07-09  2.015873  0.915106 -0.591709 -0.729144  ... -0.194242 -0.893248   \n",
      "2024-07-10  2.004693  0.927071 -0.579495 -0.731732  ... -0.198517 -0.893548   \n",
      "2024-07-11  2.059608  0.878921 -0.582475 -0.726379  ... -0.215818 -0.889852   \n",
      "2024-07-12  2.205915  0.807055 -0.574948 -0.731782  ... -0.183873 -0.889574   \n",
      "...              ...       ...       ...       ...  ...       ...       ...   \n",
      "2024-10-09  2.215139  0.358856 -0.527931 -0.755745  ...  0.040242 -0.889079   \n",
      "2024-10-10  2.170061  0.394660 -0.541871 -0.751669  ...  0.000586 -0.887576   \n",
      "2024-10-11  2.153322  0.373344 -0.529975 -0.751052  ... -0.016547 -0.886115   \n",
      "2024-10-14  2.282024  0.397833 -0.536093 -0.755065  ... -0.009142 -0.888638   \n",
      "2024-10-15  2.353423  0.374104 -0.551768 -0.745380  ...  0.000806 -0.886493   \n",
      "\n",
      "context_id      WYNN       XEL       XOM       XYL       YUM       ZBH  \\\n",
      "date                                                                     \n",
      "2024-07-08  2.100098 -0.391990  1.154036  0.201472 -0.047866 -0.166143   \n",
      "2024-07-09  2.084515 -0.384250  1.115611  0.210641 -0.054075 -0.162703   \n",
      "2024-07-10  2.052475 -0.376590  1.129429  0.224744 -0.054788 -0.170124   \n",
      "2024-07-11  1.931270 -0.364231  1.095367  0.223943 -0.062744 -0.162379   \n",
      "2024-07-12  1.941039 -0.370950  1.088016  0.228609 -0.053567 -0.169979   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "2024-10-09  2.150333 -0.399136  0.950943  0.116308 -0.011226 -0.232265   \n",
      "2024-10-10  2.178057 -0.400579  0.981017  0.089573 -0.006708 -0.228484   \n",
      "2024-10-11  2.171359 -0.405155  0.983791  0.107192 -0.020751 -0.227727   \n",
      "2024-10-14  2.189629 -0.393747  0.968899  0.106061 -0.018872 -0.221463   \n",
      "2024-10-15  1.972002 -0.357531  0.899945  0.137309 -0.029067 -0.212924   \n",
      "\n",
      "context_id      ZBRA       ZTS  \n",
      "date                            \n",
      "2024-07-08  1.962487 -0.443482  \n",
      "2024-07-09  1.987336 -0.448590  \n",
      "2024-07-10  2.035825 -0.465494  \n",
      "2024-07-11  2.041406 -0.459923  \n",
      "2024-07-12  1.998553 -0.450736  \n",
      "...              ...       ...  \n",
      "2024-10-09  2.610091 -0.490843  \n",
      "2024-10-10  2.591130 -0.484671  \n",
      "2024-10-11  2.623382 -0.493147  \n",
      "2024-10-14  2.602785 -0.489912  \n",
      "2024-10-15  2.560093 -0.482800  \n",
      "\n",
      "[71 rows x 503 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Load the dataset (make sure to specify the correct file path)\n",
    "file_path = \"/home/bathsheba/Downloads/stock_sample_data.xlsx\"  # Adjust this to your file location\n",
    "data = pd.read_csv(file_path, sep='\\t')  # Use the appropriate separator\n",
    "\n",
    "# Print the full DataFrame to check the data structure (not just the first few rows)\n",
    "print(\"Full Data:\")\n",
    "print(data)\n",
    "\n",
    "# Check the column names and adjust if necessary\n",
    "print(\"Column Names:\")\n",
    "print(data.columns)\n",
    "\n",
    "# Assign column names (assuming this matches the structure of your CSV)\n",
    "data.columns = ['date', 'open', 'high', 'low', 'close', 'volume', 'context_id', 'day']\n",
    "\n",
    "# Convert relevant columns to numeric, handling non-numeric values\n",
    "data['open'] = pd.to_numeric(data['open'], errors='coerce')\n",
    "data['high'] = pd.to_numeric(data['high'], errors='coerce')\n",
    "data['low'] = pd.to_numeric(data['low'], errors='coerce')\n",
    "data['close'] = pd.to_numeric(data['close'], errors='coerce')\n",
    "data['volume'] = pd.to_numeric(data['volume'], errors='coerce')\n",
    "\n",
    "# Check if there are any NaN values after conversion\n",
    "print(\"NaN Values Check:\")\n",
    "print(data.isna().sum())\n",
    "\n",
    "# Drop rows with NaN values to avoid calculation issues\n",
    "data.dropna(subset=['open', 'high', 'low', 'close', 'volume'], inplace=True)\n",
    "\n",
    "# Calculate daily returns based on 'close' prices\n",
    "data['returns'] = data['close'].pct_change()  # Calculate percentage change in 'close' prices\n",
    "\n",
    "# Drop NaN values generated from pct_change\n",
    "data.dropna(subset=['returns'], inplace=True)\n",
    "\n",
    "# Pivot the data to get stock returns in separate columns\n",
    "returns_df = data.pivot_table(values='returns', index='date', columns='context_id')\n",
    "returns_df = returns_df.dropna()  # Drop rows with NaN values in returns\n",
    "\n",
    "# Calculate expected returns and covariance matrix for all stocks\n",
    "expected_returns = returns_df.mean() * 252  # Annualize returns\n",
    "cov_matrix = returns_df.cov() * 252  # Annualize covariance\n",
    "\n",
    "# Initial budget\n",
    "initial_budget = 1000\n",
    "\n",
    "# Portfolio optimization function\n",
    "def portfolio_optimization(weights):\n",
    "    portfolio_return = np.dot(weights, expected_returns)\n",
    "    portfolio_risk = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "    return -portfolio_return / portfolio_risk  # Negative Sharpe ratio for minimization\n",
    "\n",
    "# Constraints and bounds\n",
    "constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})  # Weights must sum to 1\n",
    "bounds = tuple((0, 1) for _ in range(len(expected_returns)))  # Weights between 0 and 1\n",
    "\n",
    "# Initial guess (equal distribution)\n",
    "initial_weights = [1 / len(expected_returns)] * len(expected_returns)\n",
    "\n",
    "# Optimize\n",
    "result = minimize(portfolio_optimization, initial_weights, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "\n",
    "# Optimized weights\n",
    "optimized_weights = result.x\n",
    "\n",
    "# Calculate amount to invest in each stock\n",
    "investment_amounts = [weight * initial_budget for weight in optimized_weights]\n",
    "\n",
    "# Output results\n",
    "stock_investments = pd.Series(investment_amounts, index=expected_returns.index)\n",
    "print(\"Optimized Stock Investments:\")\n",
    "print(stock_investments)\n",
    "\n",
    "# Optionally, print the entire returns DataFrame for inspection\n",
    "print(\"Complete Returns DataFrame:\")\n",
    "print(returns_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6b51f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Flask in /home/bathsheba/anaconda3/lib/python3.12/site-packages (3.0.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /home/bathsheba/anaconda3/lib/python3.12/site-packages (from Flask) (3.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /home/bathsheba/anaconda3/lib/python3.12/site-packages (from Flask) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /home/bathsheba/anaconda3/lib/python3.12/site-packages (from Flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /home/bathsheba/anaconda3/lib/python3.12/site-packages (from Flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /home/bathsheba/anaconda3/lib/python3.12/site-packages (from Flask) (1.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/bathsheba/anaconda3/lib/python3.12/site-packages (from Jinja2>=3.1.2->Flask) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Flask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc50118",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ee6ad78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5001\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/bathsheba/anaconda3/lib/python3.12/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/bathsheba/anaconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 1074, in launch_instance\n",
      "    app.initialize(argv)\n",
      "  File \"/home/bathsheba/anaconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 118, in inner\n",
      "    return method(app, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/bathsheba/anaconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 654, in initialize\n",
      "    self.init_sockets()\n",
      "  File \"/home/bathsheba/anaconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 331, in init_sockets\n",
      "    self.shell_port = self._bind_socket(self.shell_socket, self.shell_port)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/bathsheba/anaconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 253, in _bind_socket\n",
      "    return self._try_bind_socket(s, port)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/bathsheba/anaconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 229, in _try_bind_socket\n",
      "    s.bind(\"tcp://%s:%i\" % (self.ip, port))\n",
      "  File \"/home/bathsheba/anaconda3/lib/python3.12/site-packages/zmq/sugar/socket.py\", line 302, in bind\n",
      "    super().bind(addr)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 564, in zmq.backend.cython.socket.Socket.bind\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 28, in zmq.backend.cython.checkrc._check_rc\n",
      "zmq.error.ZMQError: Address already in use (addr='tcp://127.0.0.1:60255')\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bathsheba/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from flask import Flask, jsonify, request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Portfolio optimization function\n",
    "def portfolio_optimization(weights, expected_returns, cov_matrix):\n",
    "    portfolio_return = np.dot(weights, expected_returns)\n",
    "    portfolio_risk = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "    return -portfolio_return / portfolio_risk  # Negative Sharpe ratio for minimization\n",
    "\n",
    "# API endpoint for optimizing the portfolio\n",
    "@app.route('/api/portfolio', methods=['POST'])\n",
    "def optimize_portfolio():\n",
    "    # You can customize this part to accept data from the user if needed\n",
    "    # For now, let's use the same logic as before\n",
    "\n",
    "    # Load the dataset\n",
    "    file_path = \"/home/bathsheba/Downloads/stock_sample_data.xlsx\"  # Adjust this to your file location\n",
    "    data = pd.read_csv(file_path, sep='\\t')  # Use the appropriate separator\n",
    "\n",
    "    # Prepare the data as before...\n",
    "    # Note: Add all the preprocessing steps you have from your original code here.\n",
    "\n",
    "    # Calculate expected returns and covariance matrix for all stocks\n",
    "    expected_returns = returns_df.mean() * 252  # Annualize returns\n",
    "    cov_matrix = returns_df.cov() * 252  # Annualize covariance\n",
    "\n",
    "    # Constraints and bounds\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})  # Weights must sum to 1\n",
    "    bounds = tuple((0, 1) for _ in range(len(expected_returns)))  # Weights between 0 and 1\n",
    "    initial_weights = [1 / len(expected_returns)] * len(expected_returns)\n",
    "\n",
    "    # Optimize\n",
    "    result = minimize(portfolio_optimization, initial_weights, args=(expected_returns, cov_matrix), \n",
    "                      method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "\n",
    "    # Optimized weights\n",
    "    optimized_weights = result.x\n",
    "    stock_investments = pd.Series(optimized_weights, index=expected_returns.index)\n",
    "\n",
    "    # Return the results as JSON\n",
    "    return jsonify(stock_investments.to_dict())\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, port=5001)  # You can change the port here if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c3d92fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/bathsheba/anaconda3/lib/python3.12/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/bathsheba/anaconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 1074, in launch_instance\n",
      "    app.initialize(argv)\n",
      "  File \"/home/bathsheba/anaconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 118, in inner\n",
      "    return method(app, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/bathsheba/anaconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 654, in initialize\n",
      "    self.init_sockets()\n",
      "  File \"/home/bathsheba/anaconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 331, in init_sockets\n",
      "    self.shell_port = self._bind_socket(self.shell_socket, self.shell_port)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/bathsheba/anaconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 253, in _bind_socket\n",
      "    return self._try_bind_socket(s, port)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/bathsheba/anaconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 229, in _try_bind_socket\n",
      "    s.bind(\"tcp://%s:%i\" % (self.ip, port))\n",
      "  File \"/home/bathsheba/anaconda3/lib/python3.12/site-packages/zmq/sugar/socket.py\", line 302, in bind\n",
      "    super().bind(addr)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 564, in zmq.backend.cython.socket.Socket.bind\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 28, in zmq.backend.cython.checkrc._check_rc\n",
      "zmq.error.ZMQError: Address already in use (addr='tcp://127.0.0.1:60255')\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "mport requests\n",
    "import json\n",
    "\n",
    "# Define the API endpoint\n",
    "url = 'http://127.0.0.1:5000/optimize'\n",
    "\n",
    "# Prepare the data you want to send (this should match the expected input of your API)\n",
    "data = {\n",
    "    'tickers': ['ABT', 'ACGL', 'ADBE', 'ADI', 'ADM', 'ADP', 'ADSK', 'AEE', 'AEP', 'AES', 'AFL', 'AIG', 'AJG', 'AKAM']\n",
    "}\n",
    "\n",
    "# Send a POST request to the Flask API\n",
    "response = requests.post(url, json=data)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the JSON response\n",
    "    output = response.json()\n",
    "    print(\"Response from API:\", output)\n",
    "else:\n",
    "    print(\"Error:\", response.status_code, response.text)\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a0dd0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/bathsheba/anaconda3/lib/python3.12/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/bathsheba/anaconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 1074, in launch_instance\n",
      "    app.initialize(argv)\n",
      "  File \"/home/bathsheba/anaconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 118, in inner\n",
      "    return method(app, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/bathsheba/anaconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 654, in initialize\n",
      "    self.init_sockets()\n",
      "  File \"/home/bathsheba/anaconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 331, in init_sockets\n",
      "    self.shell_port = self._bind_socket(self.shell_socket, self.shell_port)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/bathsheba/anaconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 253, in _bind_socket\n",
      "    return self._try_bind_socket(s, port)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/bathsheba/anaconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 229, in _try_bind_socket\n",
      "    s.bind(\"tcp://%s:%i\" % (self.ip, port))\n",
      "  File \"/home/bathsheba/anaconda3/lib/python3.12/site-packages/zmq/sugar/socket.py\", line 302, in bind\n",
      "    super().bind(addr)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 564, in zmq.backend.cython.socket.Socket.bind\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 28, in zmq.backend.cython.checkrc._check_rc\n",
      "zmq.error.ZMQError: Address already in use (addr='tcp://127.0.0.1:60255')\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4361ed71",
   "metadata": {},
   "source": [
    "$$\n",
    "E(R_p) = \\sum_{i=1}^{n} w_i \\cdot R_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f9232c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
